{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "04d0eabe",
      "metadata": {
        "id": "04d0eabe"
      },
      "source": [
        "# Языковые модели\n",
        "\n",
        "Языковые модели играют важную роль в системах распознавания речи, помогая создавать более грамотные и лексически корректные тексты. В данной работе мы будем изучать нграмные языковые модели, которые позволяют довольно легко оценить вероятность и правдоподобность текста.\n",
        "\n",
        "В нграмной языковой модели, нграм - это последовательность из n слов в тексте. Например, в предложении \"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\", биграмами будут \"по-моему мы\", \"мы сэкономим\", \"сэкономим уйму\" итд. Языковые модели оценивают вероятность появления последовательности слов, исходя из статистики появления каждого из нграм в обучающей выборке.\n",
        "\n",
        "Порядком (order) нграм языковой модели называют максимальную длину нграм, которую учитывает модель.\n",
        "\n",
        "Практическая работа разделена на 2 части:\n",
        "1. Построение нграмой языковой модели - основная часть, 10 баллов\n",
        "1. Предсказание с помощью языковой модели - дополнительная часть, 6 балла\n",
        "\n",
        "\n",
        "\n",
        "Полезные сслыки:\n",
        "* arpa формат - https://cmusphinx.github.io/wiki/arpaformat/\n",
        "* обучающие материалы - https://pages.ucsd.edu/~rlevy/teaching/2015winter/lign165/lectures/lecture13/lecture13_ngrams_with_SRILM.pdf\n",
        "* обучающие материалы.2 - https://cjlise.github.io/machine-learning/N-Gram-Language-Model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4bd5c324",
      "metadata": {
        "id": "4bd5c324"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c1c1d7",
      "metadata": {
        "id": "b0c1c1d7"
      },
      "source": [
        "# 1. Построение нграмной языковой модели. (10 баллов)\n",
        "\n",
        "\n",
        "Вероятность текста с помощью нграмной языковой модели можно вычислить по формуле:\n",
        "$$ P(w_1, w_2, .., w_n) = {\\prod{{P_{i=0}^{n}(w_i| w_{i-order}, .., w_{i-1})}}} $$\n",
        "\n",
        "В простом виде, при обучении нграмной языковой модели, чтобы рассчитать условную вероятность каждой нграмы, используется формула, основанная на количестве появлений нграмы в обучающей выборке. Формула выглядит следующим образом:\n",
        "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i})} \\over {count(w_{i-order},..., w_{i-1})}} $$\n",
        "\n",
        "Поскольку униграмы не содержат в себе какого-дибо контекста, вероятность униграмы можно посчитать поделив кол-во этой слова на общее количество слов в обучающей выборке.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5837fe90",
      "metadata": {
        "id": "5837fe90"
      },
      "outputs": [],
      "source": [
        "# в первую очередь нам понадобится подсчитать статистику по обучающей выборке\n",
        "def count_ngrams(train_text: List[str], order=3, bos=True, eos=True) -> Dict[Tuple[str], int]:\n",
        "    ngrams = defaultdict(int)\n",
        "\n",
        "    for sentence in train_text:\n",
        "        # Разбиваем предложение на слова\n",
        "        words = sentence.split()\n",
        "\n",
        "        # добавляем при необходимости символ начала строки и/или конца строки\n",
        "        if bos:\n",
        "          words = ['<s>'] + words\n",
        "        if eos:\n",
        "          words = words + ['</s>']\n",
        "\n",
        "        # итерируемся по всем n-граммам\n",
        "        for n in range(1, order + 1):\n",
        "            # Генерация n-грамм\n",
        "            current_ngrams = zip(*[words[i:] for i in range(n)])\n",
        "\n",
        "            # Суммируем уже существующие данные и данные для текущего предложения\n",
        "            ngrams = dict(Counter(ngrams) + Counter(current_ngrams))\n",
        "\n",
        "    return dict(ngrams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fd69d44d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd69d44d",
        "outputId": "76baf551-af31-4bc2-e607-96d9fce40080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1a passed\n"
          ]
        }
      ],
      "source": [
        "def test_count_ngrams():\n",
        "    assert count_ngrams(['привет привет как дела'], order=1, bos=True, eos=True) == {\n",
        "        ('<s>',): 1,\n",
        "        ('привет',): 2,\n",
        "        ('как',): 1,\n",
        "        ('дела',): 1,\n",
        "        ('</s>',): 1\n",
        "    }\n",
        "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=True) == {\n",
        "        ('привет',): 2,\n",
        "        ('как',): 1,\n",
        "        ('дела',): 1,\n",
        "        ('</s>',): 1\n",
        "    }\n",
        "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=False) == {\n",
        "        ('привет',): 2,\n",
        "        ('как',): 1,\n",
        "        ('дела',): 1\n",
        "    }\n",
        "    assert count_ngrams(['привет привет как дела'], order=2, bos=False, eos=False) == {\n",
        "        ('привет',): 2,\n",
        "        ('как',): 1,\n",
        "        ('дела',): 1,\n",
        "        ('привет', 'привет'): 1,\n",
        "        ('привет', 'как'): 1,\n",
        "        ('как', 'дела'): 1\n",
        "    }\n",
        "    assert count_ngrams(['привет ' * 6], order=2, bos=False, eos=False) == {\n",
        "        ('привет',): 6,\n",
        "        ('привет', 'привет'): 5\n",
        "    }\n",
        "    result = count_ngrams(['практическое сентября',\n",
        "                           'второе практическое занятие пройдет в офлайне 32 сентября в 12 часов 32 минуты',\n",
        "                           'в офлайне в 32 12'], order=5)\n",
        "    assert result[('<s>',)] == 3\n",
        "    assert result[('32',)] == 3\n",
        "    assert result[('<s>', 'в', 'офлайне', 'в', '32')] == 1\n",
        "    assert result[('офлайне', 'в', '32', '12', '</s>')] == 1\n",
        "    print('Test 1a passed')\n",
        "\n",
        "\n",
        "test_count_ngrams()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac6e1865",
      "metadata": {
        "id": "ac6e1865"
      },
      "source": [
        "\n",
        "Простой подход к вычислению вероятностей через количество нграм имеет существенный недостаток. Если в тексте встретится нграмма, которой не было в обучающей выборке, то вероятность всего текста будет равна нулю.\n",
        "\n",
        "Чтобы избежать данного недостатка, вводится специальное сглаживание - add-k сглаживание ([Additive, Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)). Данная техника позволяет учитывать нграмы, не встретившиеся в обучающей выборке, и при этом не делает вероятность текста равной нулю.\n",
        "\n",
        "Формула сглаживания Лапласа выглядит следующим образом:\n",
        "\n",
        "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i}) + k} \\over {count(w_{i-order},..., w_{i-1}) + k*V}} $$\n",
        "\n",
        "Здесь V - количество слов в словаре, а k - гиперпараметр, который контролирует меру сглаживания. Как правило, значение k выбирается экспериментально, чтобы найти оптимальный баланс между учетом редких нграм и сохранением вероятности для часто встречающихся нграм.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "4cafb4b8",
      "metadata": {
        "id": "4cafb4b8"
      },
      "outputs": [],
      "source": [
        "def calculate_ngram_prob(ngram: Tuple[str], counts: Dict[Tuple[str], int], V=None, k=0) -> float:\n",
        "    # Получаем частоту n-граммы\n",
        "    ngram_count = counts.get(ngram, 0)\n",
        "    context_count = 0\n",
        "    n = len(ngram)\n",
        "\n",
        "    # Если n > 1, определяем контекст\n",
        "    if n > 1:\n",
        "        context = ngram[:-1]  # (n-1)-грамма\n",
        "        context_count = counts.get(context, 0)\n",
        "    # Если n == 1, то мы хотим посчитать частоты всех однословных n-грамм\n",
        "    else:\n",
        "        for ngram_text, count in counts.items():\n",
        "            # Учитываем только одномерные n-граммы\n",
        "            if len(ngram_text) == 1:\n",
        "                context_count += count\n",
        "\n",
        "    # Если размер словаря V не указан, вычисляем его через уникальные слова в counts\n",
        "    V = len(set(word for ngram in counts.keys() for word in ngram)) if V is None else V\n",
        "\n",
        "    # Лапласовское сглаживание\n",
        "    prob = (ngram_count + k) / (context_count + k * V)\n",
        "\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "60b25d7f",
      "metadata": {
        "id": "60b25d7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ea3d34-0d1b-4c38-91f6-0071fb7fd510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1.b passed\n"
          ]
        }
      ],
      "source": [
        "def test_calculate_ngram_prob():\n",
        "    counts = count_ngrams(['практическое сентября',\n",
        "                           'второе практическое занятие в офлайне 32 сентября в 12 часов 32 минуты',\n",
        "                           'в офлайне в 32 12'], order=4)\n",
        "    assert calculate_ngram_prob(('в', 'офлайне'), counts) == 0.5\n",
        "    assert calculate_ngram_prob(('в', ), counts) == 4/25\n",
        "    assert calculate_ngram_prob(('в', ), counts, k=0.5) == (4+0.5)/(25+0.5*12)\n",
        "    assert calculate_ngram_prob(('в', 'офлайне', 'в', '32'), counts) == 1.0\n",
        "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=1) == 0.1875\n",
        "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
        "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=0) == 0.0\n",
        "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=1) == 0.0625\n",
        "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
        "\n",
        "    print(\"Test 1.b passed\")\n",
        "\n",
        "\n",
        "test_calculate_ngram_prob()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da494bf0",
      "metadata": {
        "id": "da494bf0"
      },
      "source": [
        "Основной метрикой язковых моделей является перплексия.\n",
        "\n",
        "Перплексия  — безразмерная величина, мера того, насколько хорошо распределение вероятностей предсказывает выборку. Низкий показатель перплексии указывает на то, что распределение вероятности хорошо предсказывает выборку.\n",
        "\n",
        "$$ ppl = {P(w_1, w_2 ,..., w_N)^{- {1} \\over {N}}} $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "4bd1f2e5",
      "metadata": {
        "id": "4bd1f2e5"
      },
      "outputs": [],
      "source": [
        "# Языковая модель\n",
        "class NgramLM:\n",
        "    def __init__(self, order=3, bos=True, eos=True, k=1, predefined_vocab=None):\n",
        "        self.order = order\n",
        "        self.eos = eos\n",
        "        self.bos = bos\n",
        "        self.k = k\n",
        "        self.vocab = predefined_vocab\n",
        "        self.ngrams_count = None\n",
        "\n",
        "    @property\n",
        "    def V(self) -> int:\n",
        "        return len(self.vocab)\n",
        "\n",
        "    def fit(self, train_text: List[str]) -> None:\n",
        "        # гиспользуем уже реализованную функцию для генерации всех n-грамм и их\n",
        "        # количества\n",
        "        self.ngrams_count = count_ngrams(train_text, order=self.order, bos=self.bos, eos=self.eos)\n",
        "        # обновляем словарь\n",
        "        self.vocab = [ngram for ngram in self.ngrams_count.keys() if len(ngram) == 1]\n",
        "\n",
        "    def predict_ngram_log_proba(self, ngram: Tuple[str]) -> float:\n",
        "        # считаем вероятность n-граммы\n",
        "        proba = calculate_ngram_prob(ngram, self.ngrams_count, self.V, self.k)\n",
        "        # берем логарифм\n",
        "        return np.log(proba)\n",
        "\n",
        "    def predict_log_proba(self, words: List[str]) -> float:\n",
        "        # если нужно, то добавляем символ начала и/или конца строки\n",
        "        if self.bos:\n",
        "            words = ['<s>'] + words\n",
        "        if self.eos:\n",
        "            words = words + ['</s>']\n",
        "\n",
        "        logprob = 0\n",
        "        # удаляем пустые строки, чтобы не обрабатывать их в дальнейшем\n",
        "        words = [word for word in words if word.strip() != \"\"]\n",
        "\n",
        "        # применяем chain rule, чтобы посчитать логарифм вероятности всей строки\n",
        "        start = 1 - self.order\n",
        "        used_ngrams_count = 0\n",
        "\n",
        "        for i in range(len(words)):\n",
        "          # Определяем начальный индекс для текущей n-граммы\n",
        "          actual_start = max(0, i + 1 - self.order)\n",
        "\n",
        "          # Берём n-грамму, начиная с actual_start и заканчивая текущей позицией (i + 1)\n",
        "          ngram = tuple(words[actual_start:i + 1])\n",
        "\n",
        "          # Считаем логарифм вероятности для текущей n-граммы\n",
        "          logprob += self.predict_ngram_log_proba(ngram)\n",
        "\n",
        "          # Увеличиваем счётчик использованных n-грамм\n",
        "          used_ngrams_count += 1\n",
        "\n",
        "        return logprob\n",
        "\n",
        "    def ppl(self, text: List[str]) -> float:\n",
        "        # подсчет перплексии\n",
        "        # Для того, чтобы ваш код был численно стабильным,\n",
        "        # не считайте формулу напрямую, а воспользуйтесь переходом к логарифмам вероятностей\n",
        "        sum_proba = 0\n",
        "        n = 0\n",
        "\n",
        "        # итерируемся по всем строкам в тексте\n",
        "        for line in text:\n",
        "            # разбиваем на слова\n",
        "            words = line.split()\n",
        "            # считаем вероятность\n",
        "            log_proba = self.predict_log_proba(words)\n",
        "            # суммируем вероятности\n",
        "            sum_proba += log_proba\n",
        "            # суммируем количество n-грамм в текущем предложении\n",
        "            n += max(1, len(words) + 1 + self.eos)\n",
        "\n",
        "        perplexity = np.exp(-sum_proba / n)\n",
        "\n",
        "        return perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "bb0bfe64",
      "metadata": {
        "id": "bb0bfe64"
      },
      "outputs": [],
      "source": [
        "def test_lm():\n",
        "    train_data = [\"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\",\n",
        "                  \"если я сойду с ума прямо сейчас по-моему мы сэкономим уйму времени\",\n",
        "                  \"мы сэкономим уйму времени если я сейчас сойду с ума по-моему\"]\n",
        "    global lm\n",
        "    lm = NgramLM(order=2)\n",
        "    lm.fit(train_data)\n",
        "    assert lm.V == 14\n",
        "    assert np.isclose(lm.predict_log_proba(['мы']), lm.predict_log_proba([\"если\"]))\n",
        "    assert lm.predict_log_proba([\"по-моему\"]) > lm.predict_log_proba([\"если\"])\n",
        "\n",
        "    gt = ((3+1)/(41 + 14) * 1/(3+14))**(-1/2)\n",
        "    ppl = lm.ppl([''])\n",
        "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
        "\n",
        "    gt = ((3+1)/(41 + 14) * 1/(3+14) * 1/(14)) ** (-1/3)\n",
        "    ppl = lm.ppl(['ЧТО'])\n",
        "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
        "\n",
        "    test_data = [\"по-моему если я прямо сейчас сойду с ума мы сэкономим уйму времени\"]\n",
        "    ppl = lm.ppl(test_data)\n",
        "    assert round(ppl, 2) == 7.33, f\"{ppl}\"\n",
        "test_lm()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edafa0a2",
      "metadata": {
        "id": "edafa0a2"
      },
      "source": [
        "# 2. Предсказания с помощью языковой модели (6 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "85d2eb63",
      "metadata": {
        "id": "85d2eb63"
      },
      "outputs": [],
      "source": [
        "def predict_next_word(lm: NgramLM, prefix: List[str], topk=4):\n",
        "    # TODO реализуйте функцию, которая предсказывает продолжение фразы.\n",
        "    # верните topk наиболее вероятных продолжений фразы prefix\n",
        "    probabilities = []\n",
        "\n",
        "    for word in lm.vocab:\n",
        "        ngram = tuple(prefix + list(word))\n",
        "        proba = lm.predict_ngram_log_proba(ngram)\n",
        "\n",
        "        probabilities.append({\n",
        "            \"ngram\": ngram[-1],\n",
        "            \"proba\": proba,\n",
        "        })\n",
        "\n",
        "    probabilities.sort(key=lambda row: row[\"proba\"], reverse=True)\n",
        "    probabilities = probabilities[:topk]\n",
        "\n",
        "    next_words = [(row[\"ngram\"], row[\"proba\"]) for row in probabilities]\n",
        "    return next_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word(lm, [\"ума\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stxtoh3pt3rN",
        "outputId": "c29a160f-1f2c-415b-bd1e-eab4fb69a4eb"
      },
      "id": "Stxtoh3pt3rN",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('прямо', -1.7346010553881064),\n",
              " ('по-моему', -2.1400661634962708),\n",
              " ('<s>', -2.833213344056216),\n",
              " ('мы', -2.833213344056216)]"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc4846b",
      "metadata": {
        "id": "3fc4846b"
      },
      "source": [
        "Попробуйте обучить ngram языковую модель на нескольких стихотворениях. Не забудьте трансформировать стихотворение в удобный для ngram модели формат (как сделать так, чтобы модель моделировала рифму?).\n",
        "Попробуйте сгенерировать продолжение для стихотворения с помощью такой языковой модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "107862fe",
      "metadata": {
        "id": "107862fe"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "    Как-то в полночь, в час угрюмый, полный тягостною думой,\n",
        "    Над старинными томами я склонялся в полусне,\n",
        "    Грезам странным отдавался, — вдруг неясный звук раздался,\n",
        "    Будто кто-то постучался — постучался в дверь ко мне.\n",
        "    «Это, верно, — прошептал я, — гость в полночной тишине,\n",
        "    Гость стучится в дверь ко мне».\n",
        "    Ясно помню… Ожиданье… Поздней осени рыданья…\n",
        "    И в камине очертанья тускло тлеющих углей…\n",
        "    О, как жаждал я рассвета, как я тщетно ждал ответа\n",
        "    На страданье без привета, на вопрос о ней, о ней —\n",
        "    О Леноре, что блистала ярче всех земных огней, —\n",
        "    О светиле прежних дней.\n",
        "    И завес пурпурных трепет издавал как будто лепет,\n",
        "    Трепет, лепет, наполнявший темным чувством сердце мне.\n",
        "    Непонятный страх смиряя, встал я с места, повторяя:\n",
        "    «Это только гость, блуждая, постучался в дверь ко мне,\n",
        "    Поздний гость приюта просит в полуночной тишине —\n",
        "    Гость стучится в дверь ко мне».\n",
        "    «Подавив свои сомненья, победивши опасенья,\n",
        "    Я сказал: «Не осудите замедленья моего!\n",
        "    Этой полночью ненастной я вздремнул, — и стук неясный\n",
        "    Слишком тих был, стук неясный, — и не слышал я его,\n",
        "    Я не слышал…» — тут раскрыл я дверь жилища моего:\n",
        "    Тьма — и больше ничего.\n",
        "    Взор застыл, во тьме стесненный, и стоял я изумленный,\n",
        "    Снам отдавшись, недоступным на земле ни для кого;\n",
        "    Но как прежде ночь молчала, тьма душе не отвечала,\n",
        "    Лишь — «Ленора!» — прозвучало имя солнца моего, —\n",
        "    Это я шепнул, и эхо повторило вновь его, —\n",
        "    Эхо, больше ничего.\n",
        "    Вновь я в комнату вернулся — обернулся — содрогнулся, —\n",
        "    Стук раздался, но слышнее, чем звучал он до того.\n",
        "    «Верно, что-нибудь сломилось, что-нибудь пошевелилось,\n",
        "    Там, за ставнями, забилось у окошка моего,\n",
        "    Это — ветер, — усмирю я трепет сердца моего, —\n",
        "    Ветер — больше ничего».\n",
        "    Я толкнул окно с решеткой, — тотчас важною походкой\n",
        "    Из-за ставней вышел Ворон, гордый Ворон старых дней,\n",
        "    Не склонился он учтиво, но, как лорд, вошел спесиво\n",
        "    И, взмахнув крылом лениво, в пышной важности своей\n",
        "    Он взлетел на бюст Паллады, что над дверью был моей,\n",
        "    Он взлетел — и сел над ней.\n",
        "    От печали я очнулся и невольно усмехнулся,\n",
        "    Видя важность этой птицы, жившей долгие года.\n",
        "    «Твой хохол ощипан славно, и глядишь ты презабавно, —\n",
        "    Я промолвил, — но скажи мне: в царстве тьмы, где ночь всегда,\n",
        "    Как ты звался, гордый Ворон, там, где ночь царит всегда?»\n",
        "    Молвил Ворон: «Никогда».\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43jh3MkYySEF",
        "outputId": "503f34d2-bfe6-4aef-b7e4-3942ab4d9e60"
      },
      "id": "43jh3MkYySEF",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # Приводим к нижнему регистру\n",
        "    normalized = text.strip().lower()\n",
        "\n",
        "    # Удаляем все, кроме букв, цифр, тире, пробелов и разделителей предложений\n",
        "    normalized = re.sub(r\"[^\\w\\d\\.\\?!\\-\\s]\", \" \", normalized)\n",
        "\n",
        "    # Удаляем тире между словами и лишние пробелы\n",
        "    normalized = re.sub(r\"\\s*-\\s*\", \" \", normalized)\n",
        "    normalized = re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "    # Используем nltk для разбивки на предложения\n",
        "    sentences = nltk.tokenize.sent_tokenize(normalized)\n",
        "\n",
        "    # Удаляем точки в конце предложений и другие знаки препинания\n",
        "    sentences = [re.sub(r\"[\\.!?]\", \"\", sentence).strip() for sentence in sentences]\n",
        "\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "pmvCKVlRunbw"
      },
      "id": "pmvCKVlRunbw",
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = preprocess(text)"
      ],
      "metadata": {
        "id": "hhlVb2UFvOwY"
      },
      "id": "hhlVb2UFvOwY",
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XebYUjlkv7KO",
        "outputId": "d7a5aa83-a90b-428d-d0ba-c88fbe81c918"
      },
      "id": "XebYUjlkv7KO",
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['как то в полночь в час угрюмый полный тягостною думой над старинными томами я склонялся в полусне грезам странным отдавался вдруг неясный звук раздался будто кто то постучался постучался в дверь ко мне',\n",
              " 'это верно прошептал я гость в полночной тишине гость стучится в дверь ко мне',\n",
              " 'ясно помню ожиданье поздней осени рыданья и в камине очертанья тускло тлеющих углей о как жаждал я рассвета как я тщетно ждал ответа на страданье без привета на вопрос о ней о ней о леноре что блистала ярче всех земных огней о светиле прежних дней',\n",
              " 'и завес пурпурных трепет издавал как будто лепет трепет лепет наполнявший темным чувством сердце мне',\n",
              " 'непонятный страх смиряя встал я с места повторяя это только гость блуждая постучался в дверь ко мне поздний гость приюта просит в полуночной тишине гость стучится в дверь ко мне',\n",
              " 'подавив свои сомненья победивши опасенья я сказал не осудите замедленья моего',\n",
              " 'этой полночью ненастной я вздремнул и стук неясный слишком тих был стук неясный и не слышал я его я не слышал тут раскрыл я дверь жилища моего тьма и больше ничего',\n",
              " 'взор застыл во тьме стесненный и стоял я изумленный снам отдавшись недоступным на земле ни для кого но как прежде ночь молчала тьма душе не отвечала лишь ленора',\n",
              " 'прозвучало имя солнца моего это я шепнул и эхо повторило вновь его эхо больше ничего',\n",
              " 'вновь я в комнату вернулся обернулся содрогнулся стук раздался но слышнее чем звучал он до того',\n",
              " 'верно что нибудь сломилось что нибудь пошевелилось там за ставнями забилось у окошка моего это ветер усмирю я трепет сердца моего ветер больше ничего',\n",
              " 'я толкнул окно с решеткой тотчас важною походкой из за ставней вышел ворон гордый ворон старых дней не склонился он учтиво но как лорд вошел спесиво и взмахнув крылом лениво в пышной важности своей он взлетел на бюст паллады что над дверью был моей он взлетел и сел над ней',\n",
              " 'от печали я очнулся и невольно усмехнулся видя важность этой птицы жившей долгие года',\n",
              " 'твой хохол ощипан славно и глядишь ты презабавно я промолвил но скажи мне в царстве тьмы где ночь всегда как ты звался гордый ворон там где ночь царит всегда',\n",
              " 'молвил ворон никогда']"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm = NgramLM(order=2, bos=False, eos=False)\n",
        "lm.fit(sentences)"
      ],
      "metadata": {
        "id": "-l9Fag0Hv7zI"
      },
      "id": "-l9Fag0Hv7zI",
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_word = \"ворон\"\n",
        "length = 10\n",
        "\n",
        "answer = first_word\n",
        "next_word = first_word\n",
        "\n",
        "for _ in range(0, length):\n",
        "    next_word = predict_next_word(lm, [next_word], topk=1)[0][0]\n",
        "    answer += \" \" + next_word\n",
        "\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b7wjhukCwIDr",
        "outputId": "b2686c4a-6c51-443a-f129-a8ca0df450d5"
      },
      "id": "b7wjhukCwIDr",
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ворон там за ставнями забилось у окошка моего это я в'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Попробуем добавить разметку рифмы\n",
        "\n",
        "Для этого будет разбивать по строкам, а не по предложениям. Попробуем использовать также библиотеку pronouncing для определения наличия рифмы.\n"
      ],
      "metadata": {
        "id": "pR9IzEfFwsCq"
      },
      "id": "pR9IzEfFwsCq"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pronouncing\n",
        "import pronouncing"
      ],
      "metadata": {
        "id": "fZForbd_3AkJ"
      },
      "id": "fZForbd_3AkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_last_word(line: str) -> str:\n",
        "    # Получаем последнее слово в строке\n",
        "    words = line.split()\n",
        "    return words[-1] if words else \"\"\n",
        "\n",
        "def add_rhyme_labels(text: list) -> list:\n",
        "    # Добавляем метки рифмы к строкам\n",
        "    rhyme_groups = defaultdict(list)\n",
        "\n",
        "    # Группируем строки по рифмам их последних слов\n",
        "    for idx, line in enumerate(text):\n",
        "        last_word = get_last_word(line)\n",
        "        # Получаем рифмы для последнего слова\n",
        "        rhymes = pronouncing.rhymes(last_word)\n",
        "\n",
        "        # Если рифмы найдены, используем их для создания меток\n",
        "        if rhymes:\n",
        "            # Добавляем текущую строку в группу рифм\n",
        "            rhyme_groups[last_word].extend([idx] + [text.index(rhyme) for rhyme in rhymes if rhyme in text])\n",
        "        else:\n",
        "            # Если рифм нет, используем последние 2 буквы как признак рифмы\n",
        "            rhyme_groups[last_word[-2:]].append(idx)\n",
        "\n",
        "    labeled_lines = text[:]\n",
        "    rhyme_label = 1\n",
        "    for group in rhyme_groups.values():\n",
        "        label = f\"_rhyme{rhyme_label}\"\n",
        "        for idx in group:\n",
        "            labeled_lines[idx] += label\n",
        "        rhyme_label += 1\n",
        "\n",
        "    return labeled_lines"
      ],
      "metadata": {
        "id": "F1oxLz-KwwdE"
      },
      "id": "F1oxLz-KwwdE",
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = text.split('\\n')\n",
        "\n",
        "normalized_lines = []\n",
        "for line in lines:\n",
        "  normalized = line.strip().lower()\n",
        "  # Удаляем все, кроме букв, цифр, тире, пробелов и разделителей предложений\n",
        "  normalized = re.sub(r\"[^\\w\\d\\.\\?!\\-\\s]\", \" \", normalized)\n",
        "\n",
        "  # Удаляем тире между словами и лишние пробелы\n",
        "  normalized = re.sub(r\"\\s*-\\s*\", \" \", normalized)\n",
        "  normalized = re.sub(r\"\\s+\", \" \", normalized).strip()\n",
        "\n",
        "  # Удаляем точки в конце предложений и другие знаки препинания\n",
        "  normalized = re.sub(r\"[\\.!?]\", \"\", normalized).strip()\n",
        "  normalized_lines.append(normalized)"
      ],
      "metadata": {
        "id": "JB-8g_h8znHu"
      },
      "id": "JB-8g_h8znHu",
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_lines = list(filter(None, normalized_lines))"
      ],
      "metadata": {
        "id": "TIiXQiaD1tL3"
      },
      "id": "TIiXQiaD1tL3",
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crylCvMG11ZK",
        "outputId": "4d235b0c-f997-4d7d-df7b-39f266889dd4"
      },
      "id": "crylCvMG11ZK",
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['как то в полночь в час угрюмый полный тягостною думой',\n",
              " 'над старинными томами я склонялся в полусне',\n",
              " 'грезам странным отдавался вдруг неясный звук раздался',\n",
              " 'будто кто то постучался постучался в дверь ко мне',\n",
              " 'это верно прошептал я гость в полночной тишине',\n",
              " 'гость стучится в дверь ко мне',\n",
              " 'ясно помню ожиданье поздней осени рыданья',\n",
              " 'и в камине очертанья тускло тлеющих углей',\n",
              " 'о как жаждал я рассвета как я тщетно ждал ответа',\n",
              " 'на страданье без привета на вопрос о ней о ней',\n",
              " 'о леноре что блистала ярче всех земных огней',\n",
              " 'о светиле прежних дней',\n",
              " 'и завес пурпурных трепет издавал как будто лепет',\n",
              " 'трепет лепет наполнявший темным чувством сердце мне',\n",
              " 'непонятный страх смиряя встал я с места повторяя',\n",
              " 'это только гость блуждая постучался в дверь ко мне',\n",
              " 'поздний гость приюта просит в полуночной тишине',\n",
              " 'гость стучится в дверь ко мне',\n",
              " 'подавив свои сомненья победивши опасенья',\n",
              " 'я сказал не осудите замедленья моего',\n",
              " 'этой полночью ненастной я вздремнул и стук неясный',\n",
              " 'слишком тих был стук неясный и не слышал я его',\n",
              " 'я не слышал тут раскрыл я дверь жилища моего',\n",
              " 'тьма и больше ничего',\n",
              " 'взор застыл во тьме стесненный и стоял я изумленный',\n",
              " 'снам отдавшись недоступным на земле ни для кого',\n",
              " 'но как прежде ночь молчала тьма душе не отвечала',\n",
              " 'лишь ленора прозвучало имя солнца моего',\n",
              " 'это я шепнул и эхо повторило вновь его',\n",
              " 'эхо больше ничего',\n",
              " 'вновь я в комнату вернулся обернулся содрогнулся',\n",
              " 'стук раздался но слышнее чем звучал он до того',\n",
              " 'верно что нибудь сломилось что нибудь пошевелилось',\n",
              " 'там за ставнями забилось у окошка моего',\n",
              " 'это ветер усмирю я трепет сердца моего',\n",
              " 'ветер больше ничего',\n",
              " 'я толкнул окно с решеткой тотчас важною походкой',\n",
              " 'из за ставней вышел ворон гордый ворон старых дней',\n",
              " 'не склонился он учтиво но как лорд вошел спесиво',\n",
              " 'и взмахнув крылом лениво в пышной важности своей',\n",
              " 'он взлетел на бюст паллады что над дверью был моей',\n",
              " 'он взлетел и сел над ней',\n",
              " 'от печали я очнулся и невольно усмехнулся',\n",
              " 'видя важность этой птицы жившей долгие года',\n",
              " 'твой хохол ощипан славно и глядишь ты презабавно',\n",
              " 'я промолвил но скажи мне в царстве тьмы где ночь всегда',\n",
              " 'как ты звался гордый ворон там где ночь царит всегда',\n",
              " 'молвил ворон никогда']"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rhymed = add_rhyme_labels(normalized_lines)"
      ],
      "metadata": {
        "id": "pO-0Kya4xNDK"
      },
      "id": "pO-0Kya4xNDK",
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rhymed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XAsBngQxTmy",
        "outputId": "183bbd43-1d4c-49e8-c198-bc6447ce0b2d"
      },
      "id": "7XAsBngQxTmy",
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['как то в полночь в час угрюмый полный тягостною думой_rhyme1',\n",
              " 'над старинными томами я склонялся в полусне_rhyme2',\n",
              " 'грезам странным отдавался вдруг неясный звук раздался_rhyme3',\n",
              " 'будто кто то постучался постучался в дверь ко мне_rhyme2',\n",
              " 'это верно прошептал я гость в полночной тишине_rhyme2',\n",
              " 'гость стучится в дверь ко мне_rhyme2',\n",
              " 'ясно помню ожиданье поздней осени рыданья_rhyme4',\n",
              " 'и в камине очертанья тускло тлеющих углей_rhyme5',\n",
              " 'о как жаждал я рассвета как я тщетно ждал ответа_rhyme6',\n",
              " 'на страданье без привета на вопрос о ней о ней_rhyme5',\n",
              " 'о леноре что блистала ярче всех земных огней_rhyme5',\n",
              " 'о светиле прежних дней_rhyme5',\n",
              " 'и завес пурпурных трепет издавал как будто лепет_rhyme7',\n",
              " 'трепет лепет наполнявший темным чувством сердце мне_rhyme2',\n",
              " 'непонятный страх смиряя встал я с места повторяя_rhyme8',\n",
              " 'это только гость блуждая постучался в дверь ко мне_rhyme2',\n",
              " 'поздний гость приюта просит в полуночной тишине_rhyme2',\n",
              " 'гость стучится в дверь ко мне_rhyme2',\n",
              " 'подавив свои сомненья победивши опасенья_rhyme4',\n",
              " 'я сказал не осудите замедленья моего_rhyme9',\n",
              " 'этой полночью ненастной я вздремнул и стук неясный_rhyme10',\n",
              " 'слишком тих был стук неясный и не слышал я его_rhyme9',\n",
              " 'я не слышал тут раскрыл я дверь жилища моего_rhyme9',\n",
              " 'тьма и больше ничего_rhyme9',\n",
              " 'взор застыл во тьме стесненный и стоял я изумленный_rhyme10',\n",
              " 'снам отдавшись недоступным на земле ни для кого_rhyme9',\n",
              " 'но как прежде ночь молчала тьма душе не отвечала_rhyme11',\n",
              " 'лишь ленора прозвучало имя солнца моего_rhyme9',\n",
              " 'это я шепнул и эхо повторило вновь его_rhyme9',\n",
              " 'эхо больше ничего_rhyme9',\n",
              " 'вновь я в комнату вернулся обернулся содрогнулся_rhyme3',\n",
              " 'стук раздался но слышнее чем звучал он до того_rhyme9',\n",
              " 'верно что нибудь сломилось что нибудь пошевелилось_rhyme12',\n",
              " 'там за ставнями забилось у окошка моего_rhyme9',\n",
              " 'это ветер усмирю я трепет сердца моего_rhyme9',\n",
              " 'ветер больше ничего_rhyme9',\n",
              " 'я толкнул окно с решеткой тотчас важною походкой_rhyme1',\n",
              " 'из за ставней вышел ворон гордый ворон старых дней_rhyme5',\n",
              " 'не склонился он учтиво но как лорд вошел спесиво_rhyme13',\n",
              " 'и взмахнув крылом лениво в пышной важности своей_rhyme5',\n",
              " 'он взлетел на бюст паллады что над дверью был моей_rhyme5',\n",
              " 'он взлетел и сел над ней_rhyme5',\n",
              " 'от печали я очнулся и невольно усмехнулся_rhyme3',\n",
              " 'видя важность этой птицы жившей долгие года_rhyme14',\n",
              " 'твой хохол ощипан славно и глядишь ты презабавно_rhyme15',\n",
              " 'я промолвил но скажи мне в царстве тьмы где ночь всегда_rhyme14',\n",
              " 'как ты звался гордый ворон там где ночь царит всегда_rhyme14',\n",
              " 'молвил ворон никогда_rhyme14']"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lm_r = NgramLM(order=2, eos=False, bos=False)\n",
        "lm_r.fit(rhymed)"
      ],
      "metadata": {
        "id": "mnTnNIvBx3Av"
      },
      "id": "mnTnNIvBx3Av",
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_word = \"ворон\"\n",
        "length = 10\n",
        "\n",
        "answer = first_word\n",
        "next_word = first_word\n",
        "\n",
        "for _ in range(0, length):\n",
        "    next_word = predict_next_word(lm_r, [next_word], topk=1)[0][0]\n",
        "    answer += \" \" + next_word\n",
        "\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kiV9baIMx4wo",
        "outputId": "67c15cfa-198d-432b-91dc-c0a79a820e2b"
      },
      "id": "kiV9baIMx4wo",
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ворон там за ставнями забилось у окошка моего_rhyme9 как то в'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}